{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3cf973d-55ce-48aa-bb44-6dba8171e92b",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0b940f-16a6-4d88-a842-23f36bcded1c",
   "metadata": {},
   "source": [
    "## STILL IN THE PROCESS becuase I struggle with web srapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6255ee-b3d2-4ba0-947f-8ad0d2df4f10",
   "metadata": {},
   "source": [
    "This is the second version of the Linear regression for the IMBd movie dataset.\n",
    "\n",
    "This version containts 2 datasets:\n",
    "1 - original one\n",
    "2 - more data from web scrapping\n",
    "\n",
    "All steps will be repeated but in the beginning we will upload 2 datasets insted of one and combine them. \n",
    "\n",
    "It's important to note that the results may vary compared to the initial analysis. I will comment on the metrics and provide insights in the analysis section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bbec1d-53b7-482d-a476-952623a74b8d",
   "metadata": {},
   "source": [
    "**Cleaning and modifying data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1913ee10-1f70-4756-9f30-236d19867fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc4dd6c4-940a-4d59-b6bd-c3ad0e656489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading dataset to juputer notebook\n",
    "df_1 = pd.read_csv(\"imdb_movie_data_2023.csv\")\n",
    "df_2 = pd.read_csv(\"New_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b670974e-6bb8-4d3a-a228-7674fa1675e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df_1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c67e8fa6-1ea9-4a44-b273-10eb85ed3109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    1950\n",
      "Moive Name    1950\n",
      "Rating        1944\n",
      "Votes         1944\n",
      "Meta Score    1833\n",
      "Genre         1833\n",
      "PG Rating     1874\n",
      "Year          1950\n",
      "Duration      1948\n",
      "Cast          1833\n",
      "Director      1833\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_counts = df_1.count()\n",
    "\n",
    "print(column_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "251bd824-f751-46e0-b806-6ae7dec261f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    1750\n",
      "Movie Name    1750\n",
      "Rating         255\n",
      "Votes          255\n",
      "Meta Score      58\n",
      "Genre           58\n",
      "PG Rating        0\n",
      "Year             0\n",
      "Duration         0\n",
      "Cast            57\n",
      "Director        58\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_counts = df_2.count()\n",
    "\n",
    "print(column_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "837dc6a4-a905-424c-b922-beb1549998c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ecbe6ba-21e0-4e17-a7e4-2dd7c867e5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/tcwl5glj0blfftjn4df0129r0000gn/T/ipykernel_90102/30573836.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df_1.append(df_2, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df1 and df2 are your DataFrames\n",
    "df = df_1.append(df_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ce7cb22-04a4-4987-a378-e328bbf8dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1, df_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e33b234-5a9d-4e3c-afd3-6e707e022223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3700, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36275f6d-79c4-4601-9654-558e7d9cdacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Meta Score</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3700.000000</td>\n",
       "      <td>2199.000000</td>\n",
       "      <td>2.199000e+03</td>\n",
       "      <td>1891.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>927.202703</td>\n",
       "      <td>6.847794</td>\n",
       "      <td>2.390762e+05</td>\n",
       "      <td>62.261237</td>\n",
       "      <td>2006.976410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>538.775834</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>3.077491e+05</td>\n",
       "      <td>16.537611</td>\n",
       "      <td>15.798125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1938.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>462.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>2.800000e+04</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>924.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.470000e+05</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1387.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>3.180000e+05</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1949.000000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>2.800000e+06</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0       Rating         Votes   Meta Score         Year\n",
       "count  3700.000000  2199.000000  2.199000e+03  1891.000000  1950.000000\n",
       "mean    927.202703     6.847794  2.390762e+05    62.261237  2006.976410\n",
       "std     538.775834     0.999483  3.077491e+05    16.537611    15.798125\n",
       "min       0.000000     2.400000  6.000000e+00    14.000000  1938.000000\n",
       "25%     462.000000     6.300000  2.800000e+04    51.000000  1999.000000\n",
       "50%     924.500000     7.000000  1.470000e+05    63.000000  2011.000000\n",
       "75%    1387.000000     7.500000  3.180000e+05    74.000000  2019.000000\n",
       "max    1949.000000     9.800000  2.800000e+06   100.000000  2023.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44ebeef0-97d8-4c31-9046-fc8d5ea60a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    3700\n",
      "Moive Name    1950\n",
      "Rating        2199\n",
      "Votes         2199\n",
      "Meta Score    1891\n",
      "Genre         1891\n",
      "PG Rating     1874\n",
      "Year          1950\n",
      "Duration      1948\n",
      "Cast          1890\n",
      "Director      1891\n",
      "Movie Name    1750\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_counts = df.count()\n",
    "\n",
    "print(column_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c64e7ad-f439-434c-8dc0-d78411ed3b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Moive Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Meta Score</th>\n",
       "      <th>Genre</th>\n",
       "      <th>PG Rating</th>\n",
       "      <th>Year</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Director</th>\n",
       "      <th>Movie Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Leave the World Behind</td>\n",
       "      <td>6.5</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>R</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2h 18m</td>\n",
       "      <td>Julia Roberts, Mahershala Ali, Ethan Hawke, My...</td>\n",
       "      <td>Sam Esmail</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wonka</td>\n",
       "      <td>7.4</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Adventure, Comedy, Family</td>\n",
       "      <td>PG</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1h 56m</td>\n",
       "      <td>Timothée Chalamet, Gustave Die, Murray McArthu...</td>\n",
       "      <td>Paul King</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Poor Things</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>R</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2h 21m</td>\n",
       "      <td>Emma Stone, Mark Ruffalo, Willem Dafoe, Ramy Y...</td>\n",
       "      <td>Yorgos Lanthimos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Killers of the Flower Moon</td>\n",
       "      <td>7.8</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>Crime, Drama, History</td>\n",
       "      <td>R</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>3h 26m</td>\n",
       "      <td>Leonardo DiCaprio, Robert De Niro, Lily Gladst...</td>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>May December</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>R</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1h 57m</td>\n",
       "      <td>Natalie Portman, Chris Tenzis, Charles Melton,...</td>\n",
       "      <td>Todd Haynes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   Moive Name  Rating     Votes  Meta Score  \\\n",
       "0           0       Leave the World Behind     6.5   90000.0        67.0   \n",
       "1           1                        Wonka     7.4   24000.0        66.0   \n",
       "2           2                  Poor Things     8.5    6700.0        86.0   \n",
       "3           3   Killers of the Flower Moon     7.8  128000.0        89.0   \n",
       "4           4                 May December     7.0   21000.0        85.0   \n",
       "\n",
       "                       Genre PG Rating    Year Duration  \\\n",
       "0   Drama, Mystery, Thriller         R  2023.0   2h 18m   \n",
       "1  Adventure, Comedy, Family        PG  2023.0   1h 56m   \n",
       "2     Comedy, Drama, Romance         R  2023.0   2h 21m   \n",
       "3      Crime, Drama, History         R  2023.0   3h 26m   \n",
       "4              Comedy, Drama         R  2023.0   1h 57m   \n",
       "\n",
       "                                                Cast          Director  \\\n",
       "0  Julia Roberts, Mahershala Ali, Ethan Hawke, My...        Sam Esmail   \n",
       "1  Timothée Chalamet, Gustave Die, Murray McArthu...         Paul King   \n",
       "2  Emma Stone, Mark Ruffalo, Willem Dafoe, Ramy Y...  Yorgos Lanthimos   \n",
       "3  Leonardo DiCaprio, Robert De Niro, Lily Gladst...   Martin Scorsese   \n",
       "4  Natalie Portman, Chris Tenzis, Charles Melton,...       Todd Haynes   \n",
       "\n",
       "  Movie Name  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data and see how I can modify this dataset\n",
    "df.head()\n",
    "\n",
    "# I have to google some names of columns to better understand what they mean\n",
    "# Metascore is considered the rating of a film. Scores are assigned \n",
    "# to movie's reviews of large group of the world's most respected critics, \n",
    "# and weighted average are applied to summarize their opinions range.\n",
    "# https://www.imdb.com/list/ls051211184/#:~:text=Metascore%20is%20considered%20the%20rating,to%20summarize%20their%20opinions%20range.\n",
    "\n",
    "# PG rating means to what audience these movies\n",
    "# if there is any restrictions for audience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6582238-948b-43d7-9c86-353c290c1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop all NaN values\n",
    "# in order to proceed futher with all modifications\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a778202a-87ad-4be2-bc2c-aaf514e99e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "Moive Name     object\n",
       "Rating        float64\n",
       "Votes         float64\n",
       "Meta Score    float64\n",
       "Genre          object\n",
       "PG Rating      object\n",
       "Year          float64\n",
       "Duration       object\n",
       "Cast           object\n",
       "Director       object\n",
       "Movie Name     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the format of columns\n",
    "df.dtypes\n",
    "\n",
    "# I need to check and if it is possible to modify the next columns:\n",
    "# Genre, PG Rating, Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "505e41bf-90d0-4f6f-91ce-e92b77a33247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can drop columns Cast and Director\n",
    "# because they containt a lot of data that cannot be modified to numeric\n",
    "# the Moive Name is unnecessary for the Linear Regression\n",
    "# that is why we also drop this column\n",
    "df = df.drop(columns=['Cast', 'Director', 'Moive Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0eae63c-1451-4fd6-aabc-01f1ea253b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting strings in the Genres column\n",
    "# based on a separator \",\"\n",
    "# and creating one-hot encoding\n",
    "genres = df['Genre'].str.get_dummies(sep=', ')\n",
    "\n",
    "# Concatenate one-hot encoded genres with original DataFrame\n",
    "df = pd.concat([df, genres], axis=1)\n",
    "\n",
    "# Dropping the original 'Genre' column\n",
    "df.drop('Genre', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4c47534-5f7b-4555-820d-6dc6fb863f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Duration',\n",
       " 'Meta Score',\n",
       " 'Movie Name',\n",
       " 'PG Rating',\n",
       " 'Rating',\n",
       " 'Unnamed: 0',\n",
       " 'Votes',\n",
       " 'Year']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that we do not have any same names of columns\n",
    "columns_list = df.columns.tolist()\n",
    "sorted_columns = sorted(columns_list)\n",
    "sorted_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b26c46d-f010-4420-9874-fa89d35ed8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PG Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie Name</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [Unnamed: 0, Rating, Votes, Meta Score, PG Rating, Year, Duration, Movie Name]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking that the conversion was correct\n",
    "# by looking at genres and their marks in movies\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "541704a1-4d6e-4609-8b13-b6a2306a7485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Meta Score</th>\n",
       "      <th>PG Rating</th>\n",
       "      <th>Year</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Movie Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Rating, Votes, Meta Score, PG Rating, Year, Duration, Movie Name]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifing the current state of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65372151-0ee8-4352-bbc5-9eeee658ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can drop \"Unnamed: 0\"\n",
    "# it was created becuse of contact of 2 df\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19a748b0-5d83-4a3c-93a8-0f3274ca7ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Meta Score</th>\n",
       "      <th>PG Rating</th>\n",
       "      <th>Year</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Movie Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Rating, Votes, Meta Score, PG Rating, Year, Duration, Movie Name]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b56bb408-27e3-4683-8b6c-ef489525690b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# I use encoder in order to make columns with only numeric data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mset_output(transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m one_hot_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df,one_hot_encoded],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mvariables)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:838\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_infrequent_enabled()\n\u001b[0;32m--> 838\u001b[0m fit_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infrequent_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infrequent_enabled:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_infrequent_category_mapping(\n\u001b[1;32m    846\u001b[0m         fit_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m], fit_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory_counts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    847\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:74\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[0;34m(self, X, handle_unknown, force_all_finite, return_counts)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 74\u001b[0m X_list, n_samples, n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m n_features\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:62\u001b[0m, in \u001b[0;36m_BaseEncoder._check_X\u001b[0;34m(self, X, force_all_finite)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_features):\n\u001b[1;32m     61\u001b[0m     Xi \u001b[38;5;241m=\u001b[39m _safe_indexing(X, indices\u001b[38;5;241m=\u001b[39mi, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m     Xi \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneeds_validation\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     X_columns\u001b[38;5;241m.\u001b[39mappend(Xi)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_columns, n_samples, n_features\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 931\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    935\u001b[0m         )\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    938\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# this makes multiple columns with the variable PG Rating\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "variables = ['PG Rating']\n",
    "\n",
    "# I use encoder in order to make columns with only numeric data\n",
    "encoder = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "one_hot_encoded = encoder.fit_transform(df[variables]).astype(int)\n",
    "df = pd.concat([df,one_hot_encoded],axis=1).drop(columns=variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb689bc-34c8-4e6c-9582-b92aa1b308fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifing the current state of the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b393cb3-b561-4e70-9fb9-b7fefccb55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can drop PG Rating_Unrated for the same reason\n",
    "# and also we can delete the last column: PG Rating_X\n",
    "# becuase we used OneHotEncoder\n",
    "df = df.drop(columns=['PG Rating_Unrated', 'PG Rating_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49afbe1-bcec-41c1-b65a-58c299870cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can start to modify the last column Duration\n",
    "# we need to remove \"h\" and \"m\" and modify the data it into minutes\n",
    "# we can make a function that convert a string column\n",
    "# into the numeric one\n",
    "def convert_to_minutes(duration_str):\n",
    "    try:\n",
    "        # if the value is already an integer, return it as is\n",
    "        if isinstance(duration_str, int):\n",
    "            return duration_str\n",
    "\n",
    "        # split the string into parts based on 'h' and 'm'\n",
    "        parts = duration_str.split()\n",
    "\n",
    "        # initialize hours and minutes\n",
    "        hours, minutes = 0, 0\n",
    "\n",
    "        # check each part and update hours or minutes accordingly\n",
    "        for part in parts:\n",
    "            if 'h' in part:\n",
    "                hours = int(part.replace('h', ''))\n",
    "            elif 'm' in part:\n",
    "                minutes = int(part.replace('m', ''))\n",
    "\n",
    "        # calculate total minutes\n",
    "        total_minutes = hours * 60 + minutes\n",
    "        return total_minutes\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {duration_str}: {e}\")\n",
    "        return pd.NA\n",
    "\n",
    "# appling the conversion function to the 'Duration' column\n",
    "df['Duration'] = df['Duration'].apply(convert_to_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59bbce-4a8d-4231-9a6a-709e0fa69209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the dataset that we finally have\n",
    "df.head()\n",
    "\n",
    "# we can that all data that we have now is numeric\n",
    "# and now we can proceed with checking the balance of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe0fc6-8359-4993-b8ab-7806f7be1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I change the view of the df in order to check some categories\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af0d11-8cfd-4c11-9b4a-0f130a5ca210",
   "metadata": {},
   "source": [
    "**Checking the balance of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc3817-5b13-4074-b21f-63e7168e3a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "\n",
    "# I need to balance these 5 columns Rating, Votes, Meta Score, Year, Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c6552b-3695-4464-824d-31702c0eeb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I calculate the total number of rows in the DataFrame\n",
    "# in order to check how many percentages of data was removed\n",
    "# after the cleaning\n",
    "original_rows = len(df)\n",
    "original_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f0cec-d04a-464c-8ba0-8dd74edd0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the Rating distribution\n",
    "sns.displot(df, x=\"Rating\")\n",
    "\n",
    "# we can notice that that the distribution is to more right side\n",
    "# it would be good to cut it until 5 on the x-axis\n",
    "# in order to make more balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedec3cd-8fa9-48f6-863d-7015078d44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out top 8%  (1 - 0.08 = 0.92) based on price to reduce amount of buildings\n",
    "df = df.query(\"Rating > Rating.quantile(0.1) and Rating < Rating.quantile(0.95)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f67f5-3524-4f8f-b0ac-1063bfe40423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now data is more balanced\n",
    "sns.displot(df, x=\"Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc494de-dc0f-48bf-adbe-5b7897e68f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I checked that I lost about 17% of data because of this outliner removing\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ca899-eb9d-446f-bf24-2130a9a484cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df, x=\"Votes\")\n",
    "# we can see that the column \"Votes\" is disbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8174876-2dab-441f-8e3c-ca7e3e1e5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's remove everything that is up than 0.85\n",
    "df = df.query(\"Votes < Votes.quantile(0.85)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001535e-000c-4e0d-933b-0e74fe124397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the data plot\n",
    "sns.displot(df, x=\"Votes\")\n",
    "\n",
    "# the daya still in not balanced but \n",
    "# we already we removed 15% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d14f32-928c-4936-a120-8f10ba89ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We still need to carry out of Meta Score, Year, Duration\n",
    "sns.displot(df, x=\"Meta Score\")\n",
    "\n",
    "# Meta Score looks pretty well\n",
    "# I will remove a little bit from bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb5bf64-908f-4bb1-98b6-ff4c5a9a1d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cutoff value for the bottom 3%\n",
    "cutoff_value = df['Meta Score'].quantile(0.03)\n",
    "\n",
    "# filter out rows where the 'Meta Score' values are below the cutoff\n",
    "df = df[df['Meta Score'] >= cutoff_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ef602-24e7-4fbf-b816-9bc33b67db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the plot\n",
    "sns.displot(df, x=\"Meta Score\")\n",
    "\n",
    "# it looks pretty balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff44e62-6e5b-4ece-a37d-3f9c65284228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that there are many outliers in the old movies\n",
    "class_counts = df['Year'].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e1683-4b29-49ae-8075-6cbff7f46b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and also there is a huge number of recent movies\n",
    "sns.displot(df, x=\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b270f-f190-4f7e-9de6-97b05ddc4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used quantiles to remove 5% from the bottom\n",
    "df = df.query('Year >= Year.quantile(q=0.05)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b09b8c-1f2f-4eee-b3c8-655cba87e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not balanced but we have less outliers\n",
    "sns.displot(df, x=\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca0dd2a-6ae4-4dcb-9a4f-2efa0f1ce638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the last column Duration\n",
    "sns.displot(df, x=\"Duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a691e8-062f-46bf-952c-818578b14ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cutoff value for the top 3%\n",
    "cutoff_value = df['Duration'].quantile(0.97)\n",
    "\n",
    "# Filter out rows where the 'Meta Score' values are above the cutoff\n",
    "df = df[df['Duration'] <= cutoff_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78591ecd-817b-49a5-ac8e-6a0a70f1ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see\n",
    "sns.displot(df, x=\"Duration\")\n",
    "\n",
    "# it is an almost perfect balance :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea13b76-c4a3-40e9-8d13-0903a055666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b2849-910e-48e9-8fad-9b21c82d8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the amount of rows in df after cleaning\n",
    "total_rows_after_cleaning = len(df)\n",
    "\n",
    "# Calculate the total percentage of data lost across all columns\n",
    "total_percentage_lost = round(((original_rows - total_rows_after_cleaning) / original_rows) * 100, 3)\n",
    "print(\"Total percentage of data lost:\", total_percentage_lost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a469101-1256-44b1-b021-e8556dcc6a6f",
   "metadata": {},
   "source": [
    "**The train/test –split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b92ec83-2a4e-4808-98c8-57c4d2fe6033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the columns so we can copy the other \n",
    "# columns into the X later easily\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b45032-ea31-4720-8e82-5f66d06f5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I define X and y -variables\n",
    "# list here independent variables\n",
    "X = df[['Votes', 'Meta Score', 'Year', 'Duration', 'Action',\n",
    "       'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
    "       'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Musical',\n",
    "       'Mystery', 'Romance', 'Sci-Fi', 'Sport', 'Thriller', 'War', 'Western',\n",
    "       'PG Rating_13+', 'PG Rating_16+', 'PG Rating_18+', 'PG Rating_Approved',\n",
    "       'PG Rating_G', 'PG Rating_GP', 'PG Rating_NC-17', 'PG Rating_PG',\n",
    "       'PG Rating_PG-13', 'PG Rating_Passed', 'PG Rating_R', 'PG Rating_TV-14',\n",
    "       'PG Rating_TV-G', 'PG Rating_TV-MA', 'PG Rating_TV-PG',\n",
    "       'PG Rating_TV-Y7']]\n",
    "\n",
    "\n",
    "# here we have only the target variable (dependent variable)\n",
    "y = df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed851985-100c-45f3-8e2c-013c4f6745bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test sets of my dataset\n",
    "# this examples reserves 20% for test data, 80% for training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938bfb56-cd73-43aa-8734-e39881f838e4",
   "metadata": {},
   "source": [
    " **Train our Linear Regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f8fe07-69bb-47ca-8481-7b934d4bc464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty linear regression model\n",
    "# and fit it with out data \n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3e397-da28-4149-a317-db8fd77010b3",
   "metadata": {},
   "source": [
    " **Error and performance metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a45167-bb42-4e27-936f-5f4afb0a6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test predictions with new data with our model\n",
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c43bc-9f69-450e-82e9-0d2434f00060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these values follow a line = good predictions\n",
    "# we basically compare the predicted values \n",
    "# to true test values and see the differences\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a87f8-b93d-40e7-9c38-b140e49739ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485636e3-238f-40f7-8987-91f06df95bd5",
   "metadata": {},
   "source": [
    "** Create a tester row for metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754cd9e6-c45d-4c5a-8d15-560015797d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try with some new imaginary data\n",
    "tester_row = {\n",
    "    'Votes': 20000, \n",
    "    'Meta Score': 54.0, \n",
    "    'Year': 2020, \n",
    "    'Duration': 117, \n",
    "    'Action': 1,'Adventure': 1, 'Animation': 1, 'Biography': 0, 'Comedy': 0, 'Crime': 0, 'Documentary': 0,\n",
    "       'Drama': 0, 'Family': 0, 'Fantasy': 0, 'History': 0, 'Horror': 0, 'Music': 0, 'Musical': 0,\n",
    "       'Mystery': 0, 'Romance': 0, 'Sci-Fi': 0, 'Sport': 0, 'Thriller': 0, 'War': 0, 'Western': 0,\n",
    "       \n",
    "    'PG Rating_13+': 1, 'PG Rating_16+': 0, 'PG Rating_18+': 0, 'PG Rating_Approved': 0,\n",
    "       'PG Rating_G': 0, 'PG Rating_GP': 0, 'PG Rating_NC-17': 0, 'PG Rating_PG': 0,\n",
    "       'PG Rating_PG-13': 0, 'PG Rating_Passed': 0, 'PG Rating_R': 0, 'PG Rating_TV-14': 0,\n",
    "       'PG Rating_TV-G': 0, 'PG Rating_TV-MA': 0, 'PG Rating_TV-PG': 0,\n",
    "       'PG Rating_TV-Y7': 0\n",
    "}\n",
    "\n",
    "# convert to pandas-format\n",
    "tester_row = pd.DataFrame([tester_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb8777d-0f5c-49d0-9e34-8961a22e36c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our model to predict our tester_row data\n",
    "result = lm.predict(tester_row)[0]\n",
    "\n",
    "print()\n",
    "print(f\"Predicted rating for this movie: {round(float(result), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962f03f-a8b5-4564-9367-dc52d8076cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower values indicate better performance - MAE, MSE, RMSE\n",
    "# R-squared: 1 is perfect, 0 is worst outcome\n",
    "\n",
    "# MAE - Mean average error\n",
    "# The average of all errors\n",
    "# Simple, but doesn't take large errors into account that much\n",
    "print(\"MAE\")\n",
    "print(round(metrics.mean_absolute_error(y_test, predictions), 2))\n",
    "\n",
    "# MSE - Mean square error\n",
    "# Errors are computed in the power of 2 (squared) => larger mistakes are emphasized\n",
    "print(\"\\nMSE\")\n",
    "print(round(metrics.mean_squared_error(y_test, predictions), 2), \"^2\")\n",
    "\n",
    "# RMSE - Root mean square error\n",
    "# the most common error metric used in regression\n",
    "# 0 = perfect RMSE-score, 1 = worst possible RMSE-score\n",
    "print('\\nRMSE:')\n",
    "print(round(np.sqrt(metrics.mean_squared_error(y_test, predictions)), 2))\n",
    "\n",
    "# R-squared. 0 = the model describes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "print('\\nR-squared:')\n",
    "print(round(metrics.r2_score(y_test, predictions), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60518f44-26e1-460a-8ff0-1e63a11c32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the prediction distribution are far from normal distribution\n",
    "# then the model is not probably good enough\n",
    "# distplot is deprecating in future pandas-version\n",
    "# unfortunately, there's no exact alternative to do this plot at the moment\n",
    "sns.distplot((y_test - predictions))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# we can see that there is a normal distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd1d9c-ed5c-4a0f-9b7b-6ec89bfa8b18",
   "metadata": {},
   "source": [
    "**Emphasizing variables that should affect the prediction greatly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa70e8-0cec-43e0-adcc-80b0802367f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instal the needed module\n",
    "import dtale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c63c19-7540-4a6c-8697-30dc3adf891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inspect correlation matrix with dtale\n",
    "# 1 = a perfect positive correlation\n",
    "# -1 = a negative correlation\n",
    "# 0 = no linear correlation between the variables\n",
    "dtale.show(df)\n",
    "\n",
    "# for more convienient usage there is an option in the right corner\n",
    "# to open in a new tab after choosing \"Correlations\" in the Vizualizse button\n",
    "\n",
    "# we can see that the table shows correlation between\n",
    "# Rating - Meta Score = 0.53\n",
    "# Rating - Votes = 0.37\n",
    "\n",
    "# and there are some surprises, f.e.,\n",
    "# Rating - Year = -0.28\n",
    "# and also Duration does not plau a significant role\n",
    "# considering this dtale table\n",
    "# Rating - Duration = 0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fdec5a-f809-44d6-b5b4-3af9ed91fbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By this dtale table I found that some columns \n",
    "# such as PG Rating_16+, PG Rating_18+, PG Rating_Approve and etc \n",
    "# have N/A values\n",
    "# first of all, I though that maybe they contain NaN values\n",
    "# I checked it\n",
    "nan_values = df.isna().sum()\n",
    "nan_values\n",
    "\n",
    "# no, all NaN are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef02639-7aab-4222-897f-69fda014cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I assumed that it simply possible that these columns \n",
    "# have all zeros\n",
    "# In this case the correlation coefficient cannot be computed \n",
    "# because the standard deviation of that variable is zero\n",
    "\n",
    "\n",
    "# check if all values in a column are zeros\n",
    "def check_column_only_zeros(column):\n",
    "    return (column == 0).all()\n",
    "\n",
    "# Check each column for only zeros\n",
    "for column in df.columns:\n",
    "    if check_column_only_zeros(df[column]):\n",
    "        print(f\"Column '{column}' contains only zeros.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd12be-984b-4190-8216-f681c0910e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can drop these columns\n",
    "df = df.drop(columns=['PG Rating_16+', 'PG Rating_18+', 'PG Rating_Approved', \n",
    "                      'PG Rating_GP', 'PG Rating_Passed', 'PG Rating_TV-G'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d849e-2bff-4474-8ef4-1ecf31e7473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the needed module\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# get the score rankings\n",
    "f_values, _ = f_classif(X, y)\n",
    "\n",
    "# Create a pandas Series for easier interpretation\n",
    "feat_importances = pd.Series(f_values, index=X.columns)\n",
    "\n",
    "# Plot the ANOVA F-value scores\n",
    "plt.figure(figsize=(10, 8))  # the figure size\n",
    "feat_importances.plot(kind='barh')\n",
    "plt.xlabel('Significant value')\n",
    "plt.ylabel('Columns')\n",
    "plt.title('How statistically significant each variable is in the dataset')\n",
    "plt.tight_layout()  # spacing to prevent overlapping\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Here we can see that for some unknown reasons\n",
    "# the Drama column is importnant\n",
    "# but as we saw earlier ones of the most significant \n",
    "# are Votes, Meta Score, Year, Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9b48b-8c85-4164-9e34-f8f209d0db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed modules\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Assuming X is a feature matrix and y is a target variable\n",
    "# Replace X and y with my actual data\n",
    "selector = SelectKBest(score_func=f_regression, k=10)  # Select top 10 features\n",
    "selector.fit(X, y)\n",
    "\n",
    "# Get selected feature indices\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get names of selected features\n",
    "selected_features = X.columns[selected_indices]\n",
    "\n",
    "# Get F-scores of selected features\n",
    "feature_scores = selector.scores_[selected_indices]\n",
    "\n",
    "# Create DataFrame with feature names and scores\n",
    "feature_scores_df = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Score': feature_scores\n",
    "})\n",
    "\n",
    "# Sort DataFrame by score in descending order\n",
    "feature_scores_df = feature_scores_df.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# Print DataFrame\n",
    "print(feature_scores_df)\n",
    "\n",
    "\n",
    "# for some reasaons (probably for same reasons :) )\n",
    "# the Drama column has a significant effect on Rating\n",
    "# Votes, Meta Score, Year, Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b603d99-ee90-42c1-92da-de7defa1f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inspect Rating vs Drama since it's weird \n",
    "# when comparing to correlation matrix,  ANOVA F-value scores and SelectKBest\n",
    "sns.boxplot(data=df, x=\"Rating\", y=\"Drama\")\n",
    "\n",
    "# adjust the tick labels on the x-axis\n",
    "# otherwise, they are too close to each other\n",
    "plt.xticks(rotation=45)  # rotate the tick labels by 45 degrees for better readability\n",
    "plt.tight_layout()  # adjust layout to prevent clipping of labels\n",
    "plt.show()\n",
    "\n",
    "# to be honest, I am not sure that there is any use from this plot\n",
    "# let's try another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835661a5-3ec1-4484-af7c-c8e3e6bb3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can try the regresion plot\n",
    "sns.regplot(data=df, x='Rating', y='Drama')\n",
    "\n",
    "# I think, that there could be a correlation:\n",
    "# if a movie is drama -> more chances to have a better Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e653908-be57-4af4-8195-a73026ab8ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test this idea\n",
    "# the first variant with choosing the drama genre\n",
    "# let's try with some new imaginary data\n",
    "tester_row = {\n",
    "    'Votes': 20000, \n",
    "    'Meta Score': 54.0, \n",
    "    'Year': 2020, \n",
    "    'Duration': 117, \n",
    "    'Action': 0,'Adventure': 0, 'Animation': 1, 'Biography': 0, 'Comedy': 0, 'Crime': 0, 'Documentary': 0,\n",
    "       'Drama': 1, 'Family': 0, 'Fantasy': 0, 'History': 0, 'Horror': 0, 'Music': 0, 'Musical': 0,\n",
    "       'Mystery': 0, 'Romance': 0, 'Sci-Fi': 0, 'Sport': 0, 'Thriller': 0, 'War': 0, 'Western': 0,\n",
    "       \n",
    "    'PG Rating_13+': 1, 'PG Rating_16+': 0, 'PG Rating_18+': 0, 'PG Rating_Approved': 0,\n",
    "       'PG Rating_G': 0, 'PG Rating_GP': 0, 'PG Rating_NC-17': 0, 'PG Rating_PG': 0,\n",
    "       'PG Rating_PG-13': 0, 'PG Rating_Passed': 0, 'PG Rating_R': 0, 'PG Rating_TV-14': 0,\n",
    "       'PG Rating_TV-G': 0, 'PG Rating_TV-MA': 0, 'PG Rating_TV-PG': 0,\n",
    "       'PG Rating_TV-Y7': 0\n",
    "}\n",
    "\n",
    "# convert to pandas-format\n",
    "tester_row = pd.DataFrame([tester_row])\n",
    "\n",
    "# use our model to predict our tester_row data\n",
    "result = lm.predict(tester_row)[0]\n",
    "\n",
    "print()\n",
    "print(f\"Predicted rating for the movie with the Drama genre: {round(float(result), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b4f3b-78dc-435d-921c-e4b0f523d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test this idea\n",
    "# the first variant with choosing the drama genre\n",
    "# let's try with some new imaginary data\n",
    "tester_row = {\n",
    "    'Votes': 20000, \n",
    "    'Meta Score': 54.0, \n",
    "    'Year': 2020, \n",
    "    'Duration': 117, \n",
    "    'Action': 0,'Adventure': 0, 'Animation': 1, 'Biography': 0, 'Comedy': 0, 'Crime': 0, 'Documentary': 0,\n",
    "       'Drama': 0, 'Family': 0, 'Fantasy': 0, 'History': 0, 'Horror': 0, 'Music': 0, 'Musical': 0,\n",
    "       'Mystery': 0, 'Romance': 0, 'Sci-Fi': 0, 'Sport': 0, 'Thriller': 0, 'War': 0, 'Western': 0,\n",
    "       \n",
    "    'PG Rating_13+': 1, 'PG Rating_16+': 0, 'PG Rating_18+': 0, 'PG Rating_Approved': 0,\n",
    "       'PG Rating_G': 0, 'PG Rating_GP': 0, 'PG Rating_NC-17': 0, 'PG Rating_PG': 0,\n",
    "       'PG Rating_PG-13': 0, 'PG Rating_Passed': 0, 'PG Rating_R': 0, 'PG Rating_TV-14': 0,\n",
    "       'PG Rating_TV-G': 0, 'PG Rating_TV-MA': 0, 'PG Rating_TV-PG': 0,\n",
    "       'PG Rating_TV-Y7': 0\n",
    "}\n",
    "\n",
    "# convert to pandas-format\n",
    "tester_row = pd.DataFrame([tester_row])\n",
    "\n",
    "# use our model to predict our tester_row data\n",
    "result = lm.predict(tester_row)[0]\n",
    "\n",
    "print()\n",
    "print(f\"Predicted rating for the movie WITHOUT the Drama genre: {round(float(result), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db49ee-134a-449a-90ee-5211d5892aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that the Drama actually affects on the Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05703f6-b6bd-4b81-a9ef-5f960a171cba",
   "metadata": {},
   "source": [
    "**Some analysis**\n",
    "\n",
    "<br>**Where could linear regression be useful in working life?** \n",
    "I think that movie directors or investors who want to check the potential rating of a movie before its creation or investment can use linear regression.\n",
    "\n",
    "<br>**Was it easy or difficult to use?**\n",
    "For me, it was easy to implement because I understand why we should take certain steps. Also, when I had questions, the teacher answered them for me.\n",
    "\n",
    "<br>**Any ideas for optimizations?**\n",
    "I believe that after conducting further analysis and gaining a better understanding of the significance of columns, I may decide to drop some of the PG-Rating and Genre columns in the future. Additionally, it is feasible to add more data since this rating list was updated until December 15, 2023, as the dataset was generated by web scraping the official IMDb site.\n",
    "\n",
    "I also plan to incorporate more data through web scraping in future iterations. Furthermore, I think to create a simple user interface for my model, allowing users to input test values for the regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
