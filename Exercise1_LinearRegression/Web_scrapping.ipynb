{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd52ae2-25bf-4ab4-b951-b4915513fe56",
   "metadata": {},
   "source": [
    "# Web scrapping of new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c64dec-00cd-43be-86c8-a46376a69d21",
   "metadata": {},
   "source": [
    "To enhance the dataset, I chose to scrape additional data from the official IMDb website. The original dataset covered movies up to December 15, 2023, while the new dataset extends from December 16, 2023, to the present day (February 18, 2024).\n",
    "\n",
    "I extracted the same set of information from the new dataset to maintain consistency and simplify the data cleaning and modification process. Subsequently, I will create a new Jupyter notebook to combine the two datasets and repeat all subsequent steps.\n",
    "\n",
    "The data contains the following columns:\n",
    "Moive Name, Rating, Votes, Meta Score, Genre, PG Rating, Year, Duration, Cast, Director\n",
    "\n",
    "The link for getting data:\n",
    "Moive Name, Rating, Votes, Meta Score, PG Rating, Year, Duration\n",
    "https://www.imdb.com/search/title/?title_type=feature&release_date=2023-12-16,&primary_language=en\n",
    "\n",
    "Other links are created in code to get movies' information of their:\n",
    "Genre, Cast, Director\n",
    "\n",
    "*IMDb allows users to use its content for non-personal use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c837b181-e14f-4895-a8b1-5eb0a5982d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import sys\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1f741178-e9bc-4a52-9c2c-a06be50cb9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Selenium webdriver\n",
    "# we open Google Chrome\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# give a variable to the link\n",
    "# here movies after the 16.12.2023 to 18.02.2023 (today)\n",
    "url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2023-12-16,&primary_language=en\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8b294439-b0fd-4841-a1d1-26129f223d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_show_more():\n",
    "    # IMDB uses a Dynaic Show More button at the bottom of the page\n",
    "    # for loading more data, this button needs to be\n",
    "    # clicked repeatedly to load more HTML data on the page\n",
    "\n",
    "    try:\n",
    "        # add a delay before attempting to find the 'Show more' button\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # find the 'Show more' button using its XPath\n",
    "        # the Xpath is avaible to copy from the Inspect element\n",
    "        show_more_button = driver.find_element(By.XPATH , \"/html/body/div[2]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span/button\")\n",
    "        \n",
    "        # scroll to the 'Show more' button\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", show_more_button)\n",
    "        \n",
    "        # add a delay after scrolling to allow the screen to load\n",
    "        time.sleep(2)\n",
    "\n",
    "        # click the 'Show more' button\n",
    "        show_more_button.click()\n",
    "        \n",
    "        # return True if the button click was successful\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        # print an error message if clicking the 'Show more' button fails\n",
    "        print(f\"Error clicking 'show more': {e}\")\n",
    "        # return False to indicate the failure\n",
    "        return False\n",
    "\n",
    "# define the maximum number of times to press the 'Show more' button\n",
    "num_clicks = 1\n",
    "\n",
    "# click the \"show more\" button multiple times\n",
    "# in our case is 35\n",
    "for _ in range(num_clicks):\n",
    "    # call the click_show_more function and break the loop if it returns False\n",
    "    if not click_show_more():\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "90685487-b082-41ad-99af-345e832b1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function to extract rating and votes using regular expressions \n",
    "# it handles cases where vote counts contain 'K' or 'M' \n",
    "# (for thousands and millions), \n",
    "# it and returns the extracted values\n",
    "\n",
    "def get_ratings_votes(exp):\n",
    "    # Compile a regular expression pattern to match rating and votes\n",
    "    pattern = re.compile(r'(\\d+\\.\\d+?)\\s*\\(([^)]+)\\)')\n",
    "    \n",
    "    # search for the pattern in the input string\n",
    "    # exp' is a string containing rating and votes in a combined expression\n",
    "    match = pattern.search(exp)\n",
    "    \n",
    "    # define multipliers for handling 'K' and 'M' in vote counts\n",
    "    multipliers = {\"K\": 1000, \"M\": 1000000}\n",
    "    \n",
    "    if match:\n",
    "        # if a match is found:\n",
    "        if match.group(2)[-1] in multipliers:\n",
    "            # if the last character of the second group is a multiplier (K or M):\n",
    "            numeric_part, multiplier = match.group(2)[:-1], match.group(2)[-1] \n",
    "            # extract numeric part and multiplier from the second group\n",
    "            # convert numeric part to float and multiply it with corresponding multiplier\n",
    "            votes = float(numeric_part) * multipliers[multiplier]\n",
    "        else:\n",
    "            # if there's no multiplier, simply convert the second group to float\n",
    "            votes = float(match.group(2))\n",
    "        \n",
    "        # return extracted rating (converted to float) and votes\n",
    "        return float(match.group(1)), votes\n",
    "    \n",
    "    # if no match is found, return \"NA\" for both rating and votes\n",
    "    return \"NA\", \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a1e7c2d8-06d9-43a4-a044-e09fcad7c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# loading HTML data from the current page source\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# finding all the movie data elements in the HTML\n",
    "# classes may change, which could cause issues with the code\n",
    "# if it doesn't work, check for updates in class names\n",
    "movie_data = soup.findAll('div', attrs={'class': \"ipc-metadata-list-summary-item__c\"})\n",
    "\n",
    "# extracting titles of the movies\n",
    "titles = soup.findAll('h3', attrs={'class': \"ipc-title__text\"})\n",
    "# correcting the extraction of titles\n",
    "titles = [x.text.split(\".\")[1:][0].strip() if len(x.text.split(\".\")) > 1 else 'NA' for x in titles][:-1]\n",
    "\n",
    "# initializing empty lists to store movie information\n",
    "ratings = []\n",
    "votes = []\n",
    "metascores = []\n",
    "years = []\n",
    "durations = [] \n",
    "rated = []\n",
    "links = []\n",
    "\n",
    "# looping through each movie data element\n",
    "for id, movie in enumerate(movie_data):\n",
    "    \n",
    "    # extracting metadata if available\n",
    "    metadata_element = movie.find('div', attrs={\"class\": \"sc-43986a27-7 dBkaPT dli-title-metadata\"})\n",
    "    if metadata_element:\n",
    "        metadata = [x.text for x in metadata_element.find_all('span', class_='fcCUPU dli-title-metadata-item')]\n",
    "    else:\n",
    "        metadata = []\n",
    "\n",
    "    # appending metadata to respective lists\n",
    "    years.append(metadata[0] if metadata else 'NA')\n",
    "    durations.append(metadata[1] if len(metadata) > 1 else 'NA')\n",
    "    rated.append(metadata[2] if len(metadata) > 2 else 'NA')\n",
    "\n",
    "    # extracting movie link if available, otherwise storing \"NA\"\n",
    "    # this is crucial for getting more data about each movie\n",
    "    link_element = movie.find('a', attrs={\"class\": \"ipc-lockup-overlay ipc-focusable\"})\n",
    "    if link_element:\n",
    "        link = link_element.get('href')\n",
    "    else:\n",
    "        link = 'NA'\n",
    "    links.append(link)  # storing extracted link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6c1dadd0-b2d7-4a16-9eb2-2779986c1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the casts, genres and director_list from the other pages\n",
    "casts = []\n",
    "genres = []\n",
    "director_list = []\n",
    "\n",
    "# open a new weindow\n",
    "newdriver = webdriver.Chrome()\n",
    "\n",
    "#loop through each link to gather additional information\n",
    "for link in links:\n",
    "    #check if link is available\n",
    "    if link != 'NA':\n",
    "        #navigate to the IMDb page for the movie\n",
    "        newdriver.get(\"https://www.imdb.com\" + link)\n",
    "        soup = BeautifulSoup(newdriver.page_source, 'html.parser')\n",
    "        \n",
    "        #extract genre information\n",
    "        genre = soup.find('div', attrs={'class':\"ipc-chip-list__scroller\"})\n",
    "        try:\n",
    "            genres.append(\", \".join([x.text for x in genre]))\n",
    "        except:\n",
    "            genres.append(\"NA\")\n",
    "            \n",
    "        #extract cast information\n",
    "        cast = soup.findAll('div', attrs={'class': 'sc-bfec09a1-5 hNfYaW' })  \n",
    "        try:\n",
    "            casts.append(\", \".join([x for x in [x.find('a', attrs={'class': 'sc-bfec09a1-1 gCQkeh'}).text for x in cast][:4]]))\n",
    "        except:\n",
    "            casts.append(\"NA\")\n",
    "\n",
    "        #extract director information\n",
    "        director = soup.find('div', attrs={'class': 'ipc-metadata-list-item__content-container'}) \n",
    "        try:\n",
    "            director_list.append(director.text) \n",
    "        except:\n",
    "            director_list.append(\"NA\")\n",
    "\n",
    "    else:\n",
    "        genres.append(\"NA\")\n",
    "        casts.append(\"NA\")\n",
    "        director_list.append(\"NA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "54efd064-5fe3-4a69-afb8-7c8626031e05",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create a DataFrame using the extracted movie information\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m movies_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMovie Name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Column for movie titles\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Column for movie ratings\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVotes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvotes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Column for number of votes\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMeta Score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetascores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Column for metascore\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGenre\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Column for movie genres\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPG Rating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Column for movie ratings (PG)\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43myears\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# Column for release year\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDuration\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdurations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Column for movie duration\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# Column for movie cast\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDirector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirector_list\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Column for movie directors\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# save the DataFrame to a CSV file named \"webscrapping_imdb_movie_data_2024.csv\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# saving to the directory\u001b[39;00m\n\u001b[1;32m     17\u001b[0m movies_data\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata/imdb_movie_data_2023.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/internals/construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# create a DataFrame using the extracted movie information\n",
    "movies_data = pd.DataFrame({\n",
    "    \"Movie Name\": titles,        # Column for movie titles\n",
    "    \"Rating\": ratings,           # Column for movie ratings\n",
    "    \"Votes\": votes,              # Column for number of votes\n",
    "    \"Meta Score\": metascores,    # Column for metascore\n",
    "    \"Genre\": genres,             # Column for movie genres\n",
    "    \"PG Rating\": rated,          # Column for movie ratings (PG)\n",
    "    \"Year\": years,               # Column for release year\n",
    "    \"Duration\": durations,       # Column for movie duration\n",
    "    \"Cast\": casts,               # Column for movie cast\n",
    "    \"Director\": director_list   # Column for movie directors\n",
    "})\n",
    "\n",
    "# save the DataFrame to a CSV file named \"webscrapping_imdb_movie_data_2024.csv\"\n",
    "# saving to the directory\n",
    "movies_data.to_csv(\"metadata/imdb_movie_data_2023.csv\", index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
